"""
ë„¤ì´ë²„ ì§€ë„ ë¦¬ë·° í¬ë¡¤ëŸ¬ (PC ë²„ì „)
ê°€ê²Œëª…ìœ¼ë¡œ ê²€ìƒ‰ â†’ ê°€ê²Œ í´ë¦­ â†’ ë¦¬ë·° ìˆ˜ì§‘
ì‹¤í–‰: python crawlers/naver_review_crawler.py
"""

import os
import time
import urllib.parse
import psycopg2
from playwright.sync_api import sync_playwright
from dotenv import load_dotenv

load_dotenv()

# DB ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "database": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASSWORD"),
}


def get_connection():
    return psycopg2.connect(**DB_CONFIG)


def get_restaurants_to_crawl(limit=10):
    """ë¦¬ë·° ìˆ˜ì§‘í•  ê°€ê²Œ ëª©ë¡ ì¡°íšŒ"""
    conn = get_connection()
    cur = conn.cursor()
    
    try:
        # ì•„ì§ ë¦¬ë·°ê°€ ì—†ëŠ” ê°€ê²Œ
        cur.execute("""
            SELECT r.id, r.name
            FROM restaurants r
            LEFT JOIN reviews rv ON r.id = rv.restaurant_id
            WHERE rv.id IS NULL
            ORDER BY r.id
            LIMIT %s
        """, (limit,))
        
        return cur.fetchall()
    finally:
        cur.close()
        conn.close()


def save_reviews(restaurant_id, reviews):
    """ë¦¬ë·° DB ì €ì¥"""
    conn = get_connection()
    cur = conn.cursor()
    
    saved_count = 0
    try:
        for review in reviews:
            content = review.get("content", "").strip()
            if not content or len(content) < 5:
                continue
                
            cur.execute("""
                INSERT INTO reviews (restaurant_id, content, rating, reviewer_name, is_processed)
                VALUES (%s, %s, %s, %s, FALSE)
            """, (
                restaurant_id,
                content,
                review.get("rating"),
                review.get("reviewer", "ë°©ë¬¸ì"),
            ))
            saved_count += 1
        
        conn.commit()
        return saved_count
    except Exception as e:
        print(f"   âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        conn.rollback()
        return 0
    finally:
        cur.close()
        conn.close()


def crawl_reviews(page, restaurant_name, max_reviews=15):
    """
    ë„¤ì´ë²„ ì§€ë„ PCì—ì„œ ë¦¬ë·° í¬ë¡¤ë§
    """
    reviews = []
    
    try:
        # 1. ë„¤ì´ë²„ ì§€ë„ ê²€ìƒ‰ (PC ë²„ì „)
        search_query = f"{restaurant_name} ê°•ë‚¨"
        encoded_query = urllib.parse.quote(search_query)
        search_url = f"https://map.naver.com/p/search/{encoded_query}"
        
        print(f"   â†’ ê²€ìƒ‰: {search_query}")
        page.goto(search_url, timeout=30000)
        time.sleep(3)
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ ê°€ê²Œ í´ë¦­
        # iframe ì•ˆì— ìˆì„ ìˆ˜ ìˆìŒ
        try:
            # searchIframe ì°¾ê¸°
            search_iframe = page.frame_locator('#searchIframe')
            first_item = search_iframe.locator('li.VLTHu a.tzwk0, li.UEzoS a.tzwk0, a.place_bluelink').first
            
            if first_item.count() > 0:
                first_item.click()
                time.sleep(2)
            else:
                print(f"   â†’ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (iframe)")
                return []
        except Exception as e:
            print(f"   â†’ iframe ì ‘ê·¼ ì‹¤íŒ¨: {e}")
            # iframe ì—†ì´ ì§ì ‘ ì‹œë„
            first_item = page.locator('a.place_bluelink, a.tzwk0').first
            if first_item.count() > 0:
                first_item.click()
                time.sleep(2)
            else:
                return []
        
        # 3. ê°€ê²Œ ìƒì„¸ í˜ì´ì§€ì—ì„œ ë¦¬ë·° íƒ­ í´ë¦­
        try:
            # entryIframeì—ì„œ ë¦¬ë·° íƒ­ ì°¾ê¸°
            entry_iframe = page.frame_locator('#entryIframe')
            
            # ë¦¬ë·° íƒ­ í´ë¦­
            review_tab = entry_iframe.locator('a:has-text("ë¦¬ë·°"), span:has-text("ë¦¬ë·°")').first
            if review_tab.count() > 0:
                review_tab.click()
                time.sleep(2)
            
            # ìŠ¤í¬ë¡¤í•´ì„œ ë” ë§ì€ ë¦¬ë·° ë¡œë“œ
            for _ in range(3):
                entry_iframe.locator('body').evaluate("el => el.scrollBy(0, 500)")
                time.sleep(0.5)
            
            # 4. ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ
            # ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„
            review_selectors = [
                'div.pui__vn15t2 a.pui__xtsQN-',
                'a.pui__xtsQN-',
                'div.pui__xtsQN-',
                'li.pui__X35jYm div.pui__vn15t2',
                'div.place_section_content span',
                'ul.place_apply_pui li',
            ]
            
            for selector in review_selectors:
                elements = entry_iframe.locator(selector).all()
                if elements:
                    print(f"   â†’ ì…€ë ‰í„° '{selector}' ë¡œ {len(elements)}ê°œ ë°œê²¬")
                    
                    for el in elements[:max_reviews]:
                        try:
                            text = el.inner_text()
                            # í•„í„°ë§
                            if text and 10 < len(text) < 500:
                                skip_words = ['ë”ë³´ê¸°', 'ì ‘ê¸°', 'ì‹ ê³ ', 'ë„ì›€ì´', 'ê³µìœ ', 'ë‹µê¸€', 'ì‚¬ì§„']
                                if not any(w in text for w in skip_words):
                                    reviews.append({
                                        "content": text.strip(),
                                        "reviewer": "ë°©ë¬¸ì",
                                        "rating": None,
                                    })
                        except:
                            continue
                    
                    if reviews:
                        break
                        
        except Exception as e:
            print(f"   â†’ ìƒì„¸í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        
        # ì¤‘ë³µ ì œê±°
        seen = set()
        unique_reviews = []
        for r in reviews:
            if r["content"] not in seen:
                seen.add(r["content"])
                unique_reviews.append(r)
        
        return unique_reviews
        
    except Exception as e:
        print(f"   âš ï¸ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return []


def run_crawler(limit=20, max_reviews_per_place=10):
    """í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
    
    print("ğŸš€ ë„¤ì´ë²„ ì§€ë„ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘!\n")
    
    # í¬ë¡¤ë§í•  ê°€ê²Œ ëª©ë¡
    restaurants = get_restaurants_to_crawl(limit)
    print(f"ğŸ“‹ í¬ë¡¤ë§ ëŒ€ìƒ: {len(restaurants)}ê°œ ê°€ê²Œ\n")
    print("-" * 50)
    
    if not restaurants:
        print("âŒ í¬ë¡¤ë§í•  ê°€ê²Œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_reviews = 0
    success_count = 0
    
    with sync_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹¤í–‰ (í™”ë©´ ë³´ì´ê²Œ)
        browser = p.chromium.launch(headless=False)
        context = browser.new_context(
            viewport={"width": 1280, "height": 900}
        )
        page = context.new_page()
        
        for i, (rest_id, name) in enumerate(restaurants, 1):
            print(f"\n[{i}/{len(restaurants)}] {name}")
            
            # ë¦¬ë·° í¬ë¡¤ë§
            reviews = crawl_reviews(page, name, max_reviews_per_place)
            
            if reviews:
                saved = save_reviews(rest_id, reviews)
                total_reviews += saved
                success_count += 1
                print(f"   âœ… {len(reviews)}ê°œ ë¦¬ë·° â†’ {saved}ê°œ ì €ì¥")
            else:
                print(f"   âš ï¸ ë¦¬ë·° ìˆ˜ì§‘ ì‹¤íŒ¨")
            
            # ì°¨ë‹¨ ë°©ì§€
            time.sleep(3)
        
        browser.close()
    
    print("\n" + "=" * 50)
    print(f"ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
    print(f"   - ì„±ê³µ: {success_count}ê°œ ê°€ê²Œ")
    print(f"   - ì´ ë¦¬ë·°: {total_reviews}ê°œ")


def get_review_stats():
    """ë¦¬ë·° í†µê³„ ì¡°íšŒ"""
    conn = get_connection()
    cur = conn.cursor()
    
    try:
        cur.execute("SELECT COUNT(*) FROM reviews")
        total = cur.fetchone()[0]
        
        cur.execute("""
            SELECT r.name, COUNT(rv.id) as cnt
            FROM restaurants r
            JOIN reviews rv ON r.id = rv.restaurant_id
            GROUP BY r.id, r.name
            ORDER BY cnt DESC
            LIMIT 20
        """)
        top_restaurants = cur.fetchall()
        
        print(f"\nğŸ“Š ë¦¬ë·° í†µê³„")
        print("-" * 30)
        print(f"ì´ ë¦¬ë·° ìˆ˜: {total}ê°œ\n")
        
        if top_restaurants:
            print("ë¦¬ë·° ë§ì€ ê°€ê²Œ TOP 5:")
            for name, cnt in top_restaurants:
                print(f"  - {name}: {cnt}ê°œ")
    finally:
        cur.close()
        conn.close()


# =============================================
# ì‹¤í–‰
# =============================================
if __name__ == "__main__":
    run_crawler(limit=20, max_reviews_per_place=10)
    get_review_stats()